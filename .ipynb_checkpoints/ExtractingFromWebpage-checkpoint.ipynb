{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d053a17",
   "metadata": {},
   "source": [
    "# Web Extraction for Data\n",
    "\n",
    "In this notebook we use web extrating techniques to ge information from the ClinicalTrials.gov website. The website itself allows us to download ``.csv`` files which contain most of the information we require for our analysis. Nevertheless, there are some columns we want to have that are not as easily available. \n",
    "\n",
    "There are 30,000 webpages that we want to web scrape, below is a code for automated web scraping that speeds up our data collection process. We use this code to scrape :\n",
    "\n",
    "   * NCT Number (so that we can match it to the ``.csv`` files\n",
    "   * Desired enrollment \n",
    "   * Countires were the trial was conducted\n",
    "\n",
    "**Note:** If you have the NCT Number for a clinical trial you want to extract information from, you can use this code to do so. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ddc17e",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b513113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# table_data.py\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549486b3",
   "metadata": {},
   "source": [
    "## Cancer data web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f262171",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data= pd.read_csv('cancer_data.csv')\n",
    "http = urllib3.PoolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3b9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCT Numbers from the clinical trial numbers\n",
    "\n",
    "list_NCT= list(cancer_data['NCT Number'])\n",
    "URL = 'https://clinicaltrials.gov/ct2/show/record/'\n",
    "\n",
    "final_data= []\n",
    "\n",
    "for NCT in list_NCT:\n",
    "    \n",
    "    #request permission \n",
    "    req= http.request('GET', URL + str(NCT) + '/')\n",
    "    \n",
    "    #extract data\n",
    "    soup = BeautifulSoup(req.data, 'html.parser')\n",
    "    \n",
    "    #find table in webpage with the data \n",
    "    table = soup.find('table', attrs={'class': 'ct-data_table tr-data_table tr-tableStyle'})\n",
    "\n",
    "    #find all table rows\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    #print(rows)\n",
    "    \n",
    "    #extract the variable and value from rows in webpages\n",
    "    data= []\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if rows[i].th is None:\n",
    "            name= 'NA'\n",
    "        else:\n",
    "            name= rows[i].th.text\n",
    "        if rows[i].td is None:\n",
    "            value= 'NA'\n",
    "        else:\n",
    "            value= rows[i].td.text\n",
    "        data.append(tuple([name, value]))\n",
    "    \n",
    "    #create dataframe with all the values\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Value'])\n",
    "    #print(df)\n",
    "    \n",
    "    #extract enrollment, NCT number, and Countries \n",
    "    my_df= df[df['Name'].str.contains('Enrollment') | df['Name'].str.contains('NCT') | df['Name'].str.contains('Listed Location Countries') ].reset_index()\n",
    "    \n",
    "    #get rid of unnecessary strings in the values \n",
    "    my_df['Value']= my_df['Value'].str.rstrip()\n",
    "    \n",
    "    my_df['Value'][2].replace(\"\\xa0\", \"\")\n",
    "    #print(my_df)\n",
    "    \n",
    "    #print(values_df)\n",
    "    #append data we want to our final list\n",
    "    final_data.append(list(my_df['Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a697e1",
   "metadata": {},
   "source": [
    "## Save the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32676542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame with our final list \n",
    "enrollment_countries_df = pd.DataFrame(final_data, columns=['Actual', 'Estimated', 'Countries', 'NCT Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cb6413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv file\n",
    "enrollment_countries_df.to_csv('enrollment_countries_cancer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fcc350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv('enrollment_countries_cancer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15d641",
   "metadata": {},
   "source": [
    "## Cardiovascular data web scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20519910",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiovascular_data= pd.read_csv('cardiovascular_data.csv')\n",
    "http = urllib3.PoolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCT Numbers from the clinical trial numbers\n",
    "\n",
    "list_NCT= list(cardiovascular_data['NCT Number'])\n",
    "URL = 'https://clinicaltrials.gov/ct2/show/record/'\n",
    "\n",
    "final_data= []\n",
    "\n",
    "for NCT in list_NCT:\n",
    "    \n",
    "    #request permission \n",
    "    req= http.request('GET', URL + str(NCT) + '/')\n",
    "    \n",
    "    #extract data\n",
    "    soup = BeautifulSoup(req.data, 'html.parser')\n",
    "    \n",
    "    #find table in webpage with the data \n",
    "    table = soup.find('table', attrs={'class': 'ct-data_table tr-data_table tr-tableStyle'})\n",
    "\n",
    "    #find all table rows\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    #print(rows)\n",
    "    \n",
    "    #extract the variable and value from rows in webpages\n",
    "    data= []\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if rows[i].th is None:\n",
    "            name= 'NA'\n",
    "        else:\n",
    "            name= rows[i].th.text\n",
    "        if rows[i].td is None:\n",
    "            value= 'NA'\n",
    "        else:\n",
    "            value= rows[i].td.text\n",
    "        data.append(tuple([name, value]))\n",
    "    \n",
    "    #create dataframe with all the values\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Value'])\n",
    "    #print(df)\n",
    "    \n",
    "    #extract enrollment, NCT number, and Countries \n",
    "    my_df= df[df['Name'].str.contains('Enrollment') | df['Name'].str.contains('NCT') | df['Name'].str.contains('Listed Location Countries') ].reset_index()\n",
    "    \n",
    "    #get rid of unnecessary strings in the values \n",
    "    my_df['Value']= my_df['Value'].str.rstrip()\n",
    "    \n",
    "    my_df['Value'][2].replace(\"\\xa0\", \"\")\n",
    "    #print(my_df)\n",
    "    \n",
    "    #print(values_df)\n",
    "    #append data we want to our final list\n",
    "    final_data.append(list(my_df['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame with our final list \n",
    "enrollment_countries_cardiovascular = pd.DataFrame(final_data, columns=['Actual', 'Estimated', 'Countries', 'NCT Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c891ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv file\n",
    "enrollment_countries_cardiovascular.to_csv('enrollment_countries_cardiovascular.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d590d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv('enrollment_countries_cardiovascular.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b4840",
   "metadata": {},
   "source": [
    "## Respiratory diseases web scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82502f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "respiratory_data= pd.read_csv('respiratory_data.csv')\n",
    "http = urllib3.PoolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCT Numbers from the clinical trial numbers\n",
    "\n",
    "list_NCT= list(respiratory_data['NCT Number'])\n",
    "URL = 'https://clinicaltrials.gov/ct2/show/record/'\n",
    "\n",
    "final_data= []\n",
    "\n",
    "for NCT in list_NCT:\n",
    "    \n",
    "    #request permission \n",
    "    req= http.request('GET', URL + str(NCT) + '/')\n",
    "    \n",
    "    #extract data\n",
    "    soup = BeautifulSoup(req.data, 'html.parser')\n",
    "    \n",
    "    #find table in webpage with the data \n",
    "    table = soup.find('table', attrs={'class': 'ct-data_table tr-data_table tr-tableStyle'})\n",
    "\n",
    "    #find all table rows\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    #print(rows)\n",
    "    \n",
    "    #extract the variable and value from rows in webpages\n",
    "    data= []\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if rows[i].th is None:\n",
    "            name= 'NA'\n",
    "        else:\n",
    "            name= rows[i].th.text\n",
    "        if rows[i].td is None:\n",
    "            value= 'NA'\n",
    "        else:\n",
    "            value= rows[i].td.text\n",
    "        data.append(tuple([name, value]))\n",
    "    \n",
    "    #create dataframe with all the values\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Value'])\n",
    "    #print(df)\n",
    "    \n",
    "    #extract enrollment, NCT number, and Countries \n",
    "    my_df= df[df['Name'].str.contains('Enrollment') | df['Name'].str.contains('NCT') | df['Name'].str.contains('Listed Location Countries') ].reset_index()\n",
    "    \n",
    "    #get rid of unnecessary strings in the values \n",
    "    my_df['Value']= my_df['Value'].str.rstrip()\n",
    "    \n",
    "    my_df['Value'][2].replace(\"\\xa0\", \"\")\n",
    "    #print(my_df)\n",
    "    \n",
    "    #print(values_df)\n",
    "    #append data we want to our final list\n",
    "    final_data.append(list(my_df['Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44433c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame with our final list \n",
    "enrollment_countries_respiratory = pd.DataFrame(final_data, columns=['Actual', 'Estimated', 'Countries', 'NCT Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv file\n",
    "enrollment_countries_respiratory.to_csv('enrollment_countries_respiratory.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e69d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv('enrollment_countries_respiratory.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
